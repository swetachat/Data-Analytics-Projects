{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Comparision between Naive Bayes Model and Decision Tree Model for Hotel Reivew - Trip Advisor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import string\n",
    "import random\n",
    "import csv\n",
    "import nltk\n",
    "import collections\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics.scores import (accuracy, precision, recall, f_measure)\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Removing negative words from english_stops, as this is  important keywords for negative sentiments\n",
    "english_stops = set(stopwords.words('english'))\n",
    "negate_words = [\"doesn't\",\"no\",\"not\",\"didn't\",\"don't\",\"haven't\",\"shouldn't\",\"weren't\",\"won't\"]\n",
    "english_stops = [word for word in english_stops if word not in negate_words]\n",
    "\n",
    "def bow_features(review):\n",
    "    words = word_tokenize(review)\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    words = [word for word in words if word not in set(string.punctuation[1:])]\n",
    "\n",
    "    stem_list = [stemmer.stem(word) for word in words]\n",
    "    my_dict = dict([(word, True) for word in stem_list])\n",
    "    return my_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildDataSet(prefix, hotelName):\n",
    "    # Use chrome webdriver\n",
    "    browser = webdriver.Chrome()\n",
    "\n",
    "    dataset = []\n",
    "    \n",
    "    for i in range(0,10,5):\n",
    "\n",
    "        url = prefix + str(i) +\"-\"+ hotelName + \".html\"\n",
    "        browser.get(url)\n",
    "        \n",
    "        time.sleep(15)\n",
    "\n",
    "        # Find and click the \"more\" links\n",
    "        more_links = browser.find_elements_by_xpath(\"//span[@class='taLnk ulBlueLinks']\")\n",
    "        for l in more_links:\n",
    "            try:\n",
    "                l.click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Use BeautifulSoup to parse the webpages\n",
    "        html = browser.page_source\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "        # Find the review blocks\n",
    "        review_blocks = soup.find_all('div', 'reviewSelector')\n",
    "\n",
    "        for r in review_blocks:\n",
    "            int_rating = int(r.find('span','ui_bubble_rating')['class'][1].split('_')[1])//10\n",
    "\n",
    "            # Convert 1-3 rating as neg and 4-5 as pos\n",
    "            rating = \"neg\" if int_rating < 4 else \"pos\"\n",
    "\n",
    "            review = r.p.text\n",
    "            dataset.append((rating,review))      #create list of tuples with (string,string)\n",
    "           \n",
    "    browser.quit()       \n",
    "    \n",
    "    #creating list of above created tuples with each tuples as (dict,label)\n",
    "    featured_dataset =[(bow_features(dataset[i][1]), dataset[i][0]) for i in range(len(dataset))]   \n",
    "    print(\"Dataset Created\") \n",
    "    \n",
    "    return featured_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildModel(classifier, train_set,test_set):\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "   \n",
    "    #create ref and test datasets\n",
    "    for i, (feats, label) in enumerate(test_set):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    "\n",
    "    print('Accuracy:', nltk.classify.util.accuracy(classifier, test_set))\n",
    "    print('pos precision:', precision(refsets['pos'], testsets['pos']))\n",
    "    print('pos recall:', recall(refsets['pos'], testsets['pos']))\n",
    "    print('pos F-measure:', f_measure(refsets['pos'], testsets['pos']))\n",
    "    print('neg precision:', precision(refsets['neg'], testsets['neg']))\n",
    "    print('neg recall:', recall(refsets['neg'], testsets['neg']))\n",
    "    print('neg F-measure:', f_measure(refsets['neg'], testsets['neg']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Created\n",
      "<class 'list'>\n",
      "7\n",
      "--------------- Naive Bayes -----------------------\n",
      "Accuracy: 1.0\n",
      "pos precision: 1.0\n",
      "pos recall: 1.0\n",
      "pos F-measure: 1.0\n",
      "neg precision: None\n",
      "neg recall: None\n",
      "neg F-measure: None\n",
      "--------------- Decision Tree -----------------------\n",
      "Accuracy: 1.0\n",
      "pos precision: 1.0\n",
      "pos recall: 1.0\n",
      "pos F-measure: 1.0\n",
      "neg precision: None\n",
      "neg recall: None\n",
      "neg F-measure: None\n"
     ]
    }
   ],
   "source": [
    "# Building model for hotel 1\n",
    "hotel1Prefix = \"https://www.tripadvisor.com/Hotel_Review-g60763-d584986-Reviews-or\"\n",
    "hotel1 =\"Hotel_Central_Fifth_Avenue_New_York-New_York_City_New_York\"\n",
    "\n",
    "#randamize the list of tuples\n",
    "featured_dataset = buildDataSet(hotel1Prefix,hotel1)\n",
    "random.shuffle(featured_dataset)\n",
    "    \n",
    "#create the training and test set\n",
    "train_set, test_set = featured_dataset[:int(len(featured_dataset)*.75)], featured_dataset[int(len(featured_dataset)*.75):]\n",
    "\n",
    "print(type(train_set))\n",
    "print(len(train_set))\n",
    "# Train the Naive Bayes model\n",
    "nb_classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Train a decision tree model\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, binary=True, entropy_cutoff=0.8, depth_cutoff=5, support_cutoff=30)\n",
    "\n",
    "print(\"--------------- Naive Bayes -----------------------\")\n",
    "buildModel(nb_classifier,train_set,test_set)\n",
    "\n",
    "print(\"--------------- Decision Tree -----------------------\")\n",
    "buildModel(dt_classifier,train_set,test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<B> Better Model : Decision Tree </B>\n",
    "<p>Since this is Hotel review, useful for the regional manager to find the customer feedbacks. \n",
    "The actual negative reviews, will help the management to find out the areas where the corrective actions needs to be taken, to improve the customer services. \n",
    "\n",
    "The false positive are the one which are negative reviews in actual but predicted as positive reviews. The less FP the more is the precision. Model with more precision will provide more benefits.</p>\n",
    "\n",
    "<b>Precision = TP/(TP +FP)</b>\n",
    "\n",
    "Lesser FP, more is the precision, better is the model.\n",
    "\n",
    "neg Precision says the files that are neg but are incorrectly identified. \n",
    "\n",
    "For Naive Bayes the neg precision is 50% while in Decision tree the neg precision is 64%. This means there are less FP for neg class in Decision trees model.\n",
    "\n",
    "So, considering Decision as our better model, we will use it to evaluate our second hotel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Created\n",
      "--------------- Output -----------------------\n",
      "Accuracy: 0.7066666666666667\n",
      "pos precision: 0.7368421052631579\n",
      "pos recall: 0.7\n",
      "pos F-measure: 0.717948717948718\n",
      "neg precision: 0.6756756756756757\n",
      "neg recall: 0.7142857142857143\n",
      "neg F-measure: 0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "# Using Naive Bayes for second Hotel\n",
    "\n",
    "hotel2Prefix = \"https://www.tripadvisor.com/Hotel_Review-g60763-d99766-Reviews-or\"\n",
    "hotel2 = \"The_Roosevelt_Hotel-New_York_City_New_York\"\n",
    "\n",
    "#randamize the list of tuples\n",
    "featured_dataset = buildDataSet(hotel2Prefix,hotel2)\n",
    "random.shuffle(featured_dataset)\n",
    "    \n",
    "#create the training and test set\n",
    "train_set, test_set = featured_dataset[:int(len(featured_dataset)*.75)], featured_dataset[int(len(featured_dataset)*.75):]\n",
    "\n",
    "# Train a decision tree model\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set, binary=True, entropy_cutoff=0.8, depth_cutoff=5, support_cutoff=30)\n",
    "\n",
    "print(\"--------------- Output -----------------------\")\n",
    "buildModel(dt_classifier,train_set,test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><u>Results Summary</u></b>\n",
    "\n",
    "<B>2nd hotel</B> \n",
    "<br>Accuracy: 0.7066666666666667\n",
    "<br>pos precision: 0.7368421052631579\n",
    "<br>pos recall: 0.7\n",
    "<br>pos F-measure: 0.717948717948718\n",
    "<br>neg precision: 0.6756756756756757\n",
    "<br>neg recall: 0.7142857142857143\n",
    "<br>neg F-measure: 0.6944444444444444\n",
    "\n",
    "<B>1st hotel</B>\n",
    "<br>Accuracy: 0.6533333333333333\n",
    "<br>pos precision: 0.6557377049180327\n",
    "<br>pos recall: 0.8888888888888888\n",
    "<br>pos F-measure: 0.7547169811320754\n",
    "<br>neg precision: 0.6428571428571429\n",
    "<br>neg recall: 0.3\n",
    "<br>neg F-measure: 0.40909090909090906\n",
    "\n",
    " Accuracy is <b>increased</b>.\n",
    "<br>Pos Precision is <b>increased</b>.\n",
    "<br>Pos Recall is <b>decreased</b>.\n",
    "<br>Pos F-measure is <b>decreased</b>.\n",
    "<br>Neg Precision is <b>increased</b>.\n",
    "<br>Neg Recall is <b>increased</b>.\n",
    "<br>Neg F-measure is <b>increased</b>.\n",
    "\n",
    "Higher precision means <b>less false positives</b>, while a lower precision means more <b>false positives</b>. \n",
    "Higher recall means <b>less false negatives</b>, while lower recall means more <b>false negatives</b>. \n",
    "\n",
    "Increased neg precision denotes very <b>few false positive</b> for the neg class. But many files that are neg, are incorrectly classified. Increased neg recall, denotes <b> decrease false negative</b> for neg labels.\n",
    "\n",
    "Decreased pos recall denotes <b>more false negative</b>for the pos class. There are files that are pos but are incorrectly classified. Increased pos precision, denotes <b>decreased false positive</b> for pos label.\n",
    "\n",
    "\n",
    "F-measure is combination of precision and recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('know', True),\n",
       " ('charg', True),\n",
       " ('member', True),\n",
       " ('later', True),\n",
       " ('pictur', True),\n",
       " ('told', True),\n",
       " ('point', True),\n",
       " ('someon', True),\n",
       " ('tell', True),\n",
       " ('window', True)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_classifier.most_informative_features(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    know = True              neg : pos    =     10.4 : 1.0\n",
      "                   charg = True              neg : pos    =     10.4 : 1.0\n",
      "                  member = True              neg : pos    =      9.2 : 1.0\n",
      "                   later = True              neg : pos    =      8.5 : 1.0\n",
      "                  pictur = True              neg : pos    =      8.0 : 1.0\n",
      "                    told = True              neg : pos    =      7.6 : 1.0\n",
      "                   point = True              neg : pos    =      7.0 : 1.0\n",
      "                  someon = True              neg : pos    =      7.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_classifier.show_most_informative_features(n=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
